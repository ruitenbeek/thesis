{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1step_baseline.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPvKZSn5YAgs4xnbWnlHedq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruitenbeek/thesis/blob/main/1step_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEGmY-ursyyB",
        "outputId": "9dd04ab5-bff3-48c5-8d92-01a2ad2d9a20"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSH8FRtQUP5H",
        "outputId": "e4b00a7b-71e6-40a9-e3b7-deb24f36d4cd"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/thesis/code')\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/thesis/code\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7NS2qYbURzJ"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from csv import DictReader\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD78-6dtUe_B"
      },
      "source": [
        "def read_file(file):\n",
        "    data = list()\n",
        "    abu_count = 0\n",
        "    off_count = 0\n",
        "    not_count = 0\n",
        "    with open(file, 'r') as f:\n",
        "        reader = DictReader(f, delimiter='\\t')\n",
        "        for row in reader:\n",
        "            if (row['abusive'] == 'NOT' or row['abusive'] == 'UNKNOWN') and (row['explicitness'] == 'IMPLICIT' or row['explicitness'] == 'EXPLICIT'):\n",
        "                data.append([row['text'], 'OFF'])\n",
        "                off_count += 1\n",
        "            elif row['abusive'] == 'IMPLICIT' or row['abusive'] == 'EXPLICIT':\n",
        "                data.append([row['text'], 'ABU'])\n",
        "                abu_count += 1\n",
        "            elif (row['abusive'] == 'NOT' or row['abusive'] == 'UNKNOWN') and row['explicitness'] == 'NOT':\n",
        "                data.append([row['text'], 'NOT'])\n",
        "                not_count += 1\n",
        "    print(f'ABU: %i\\nOFF: %i\\nNOT: %i' % (abu_count, off_count, not_count))\n",
        "    data_df = pd.DataFrame(data)\n",
        "    data_df.columns = ['text', 'label']\n",
        "    return data_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnKDQoOkUhzX"
      },
      "source": [
        "def split_labels(data_df):\n",
        "    data_X = data_df.text.tolist()\n",
        "    data_y = data_df.label.tolist()\n",
        "    return data_X, data_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teuS9sWfUmOg"
      },
      "source": [
        "def dummy(train_X, train_y):\n",
        "    model = DummyClassifier(strategy='most_frequent')\n",
        "    model.fit(train_X, train_y)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vgzbt5HUwhN"
      },
      "source": [
        "def evaluation(model, test_X, test_y):\n",
        "    pred_y = model.predict(test_X)\n",
        "    target_names = ['ABU', 'NOT', 'OFF']\n",
        "    print(classification_report(test_y, pred_y, target_names=target_names, digits=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZSVNJrpUzJ7",
        "outputId": "ba404260-064e-405a-a4f2-e6cb68bb140b"
      },
      "source": [
        "print('###TRAIN Split###')\n",
        "train_data = read_file('train_final_pp.csv')\n",
        "print('\\n###TEST Split###')\n",
        "test_data = read_file('test_final_pp.csv')\n",
        "train_X, train_y = split_labels(train_data)\n",
        "test_X, test_y = split_labels(test_data)\n",
        "\n",
        "model = dummy(train_X, train_y)\n",
        "print('\\n####TEST Results####')\n",
        "evaluation(model, test_X, test_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###TRAIN Split###\n",
            "ABU: 1143\n",
            "OFF: 1445\n",
            "NOT: 5176\n",
            "\n",
            "###TEST Split###\n",
            "ABU: 637\n",
            "OFF: 399\n",
            "NOT: 2072\n",
            "\n",
            "####TEST Results####\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ABU       0.00      0.00      0.00       637\n",
            "         NOT       0.67      1.00      0.80      2072\n",
            "         OFF       0.00      0.00      0.00       399\n",
            "\n",
            "    accuracy                           0.67      3108\n",
            "   macro avg       0.22      0.33      0.27      3108\n",
            "weighted avg       0.44      0.67      0.53      3108\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}